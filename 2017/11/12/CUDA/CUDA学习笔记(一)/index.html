<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="CUDA,Parallel Computing," />










<meta name="description" content="这是我学习CUDA整理的笔记，从入门的第一个程序开始，主要参考教材是《CUDA by Example》。">
<meta name="keywords" content="CUDA,Parallel Computing">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA学习笔记(一)">
<meta property="og:url" content="http://yoursite.com/2017/11/12/CUDA/CUDA学习笔记(一)/index.html">
<meta property="og:site_name" content="Black Feather">
<meta property="og:description" content="这是我学习CUDA整理的笔记，从入门的第一个程序开始，主要参考教材是《CUDA by Example》。">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-08-03T12:44:48.621Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CUDA学习笔记(一)">
<meta name="twitter:description" content="这是我学习CUDA整理的笔记，从入门的第一个程序开始，主要参考教材是《CUDA by Example》。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/11/12/CUDA/CUDA学习笔记(一)/"/>





  <title>CUDA学习笔记(一) | Black Feather</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Black Feather</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/12/CUDA/CUDA学习笔记(一)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CUDA学习笔记(一)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-12T00:00:00+09:00">
                2017-11-12
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/11/12/CUDA/CUDA学习笔记(一)/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/11/12/CUDA/CUDA学习笔记(一)/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这是我学习CUDA整理的笔记，从入门的第一个程序开始，主要参考教材是《CUDA by Example》。</p>
<a id="more"></a>
<h2 id="第一个CUDA程序"><a href="#第一个CUDA程序" class="headerlink" title="第一个CUDA程序"></a>第一个CUDA程序</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">__global__ void kernel(void) &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">int main(void) &#123;</span><br><span class="line">    kernel&lt;&lt;&lt;1, 1&gt;&gt;&gt;();</span><br><span class="line">    printf(&quot;Hello, Word\n&quot;);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>与一般c的hello word不同的是，该代码有两个不同的地方：</p>
<ol>
<li>一个空函数kernel(),并且带有修饰符<strong>global</strong></li>
<li>对这个空函数的调用，并带有修饰字符&lt;&lt;&lt;1, 1&gt;&gt;&gt;</li>
</ol>
<p>__global__修饰符告诉编译器，该函数应该编译为在设备而不是主机上运行。</p>
<p>&lt;&lt;&lt;1, 1&gt;&gt;&gt;表示调用设备代码，尖括号表示将一些参数传递给运行时系统，这些参数并不是传递给设备代码的参数，而是告诉运行时如何启动设备代码。</p>
<h2 id="CUDA加法"><a href="#CUDA加法" class="headerlink" title="CUDA加法"></a>CUDA加法</h2><p>下面我们来看一个更复杂的例子，用CUDA实现GPU加法计算：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">__global__ void add(int a, int b, int *c)&#123;</span><br><span class="line">    *c = a + b;</span><br><span class="line">&#125;</span><br><span class="line">int main(void) &#123;</span><br><span class="line">    int c;</span><br><span class="line">    int *dev_c;</span><br><span class="line">    HANDLE_ERROR(cudaMalloc((void**)&amp;dev_c, sizeof(int)));</span><br><span class="line">    add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);</span><br><span class="line">    HANDLE_ERROR(cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost));</span><br><span class="line">    printf(&quot;2 + 7 = %d\n&quot;, c);</span><br><span class="line">    cudaFree(dev_c);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这段代码有两个核心概念：</p>
<ol>
<li>可以像调用c函数一样将参数传递给核函数</li>
<li>当设备执行任何有用的操作时，都需要分配内存，例如将计算值返回给主机。</li>
</ol>
<h4 id="cudaMalloc-函数"><a href="#cudaMalloc-函数" class="headerlink" title="cudaMalloc()函数"></a>cudaMalloc()函数</h4><p>设备函数调用的传参过程和普通c函数类似，需要注意的是通过’cudaMalloc()’来分配内存，<br>‘cudaMalloc()’函数告诉CUDA运行时在设备上分配内存，</p>
<pre><code>1. 第一个参数是一个指针，指向用于保存新分配内存地址的变量，
2. 第二个参数是分配内存的大小。
3. 该函数的返回类型和malloc()相同，都是&apos;void*&apos;
</code></pre><p>CUDA大大淡化了主机代码和设备代码之间的差异，但程序员一定不能在主机代码中对’cudaMalloc()’返回的指针进行读取或者写入内存。总的来说，主机指针只能访问主机代码中的内存，而设备指针只能访问设备代码中的内存。</p>
<h4 id="cudaMemcpy"><a href="#cudaMemcpy" class="headerlink" title="cudaMemcpy()"></a>cudaMemcpy()</h4><p>‘cudaMemcpy()’表示对设备指针的内容和主机指针的内容复制</p>
<pre><code>1. 第一个参数是主机指针
2. 第二个参数是设备指针
3. 第三个参数是内存大小
4. 第四个参数&apos;cudaMemcpyDeviceToHost&apos;表示从设备复制到主机，同样的&apos;cudaMemcpyHostToDevice&apos;表示主机复制到设备。&apos;cudaMemcpyDeviceToDevice&apos;表示两个指针都位于设备上。
</code></pre><h2 id="查询设备"><a href="#查询设备" class="headerlink" title="查询设备"></a>查询设备</h2><p>在编写设备代码并在GPU上进行计算时，如果程序能知道设备中拥有多少内存，都有哪些设备等信息无疑是有用的。</p>
<ol>
<li>获得支持CUDA的GPU数量：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int count;</span><br><span class="line">cudaGetDeviceCount(&amp;count);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>在获取CUDA设备数量后，可以使用’cudaGetDeviceProperties()’查询每个设备的相关信息，CUDA运行时将返回一个’cudaDeviceProp’类型的结构，包含了设备相关属性。结构内的详细信息请Google。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">intmain(void) &#123;</span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    int count;</span><br><span class="line">    cudaGetDeviceCount(count);</span><br><span class="line">    for(int i = 0;i&lt;count; i++)&#123;</span><br><span class="line">        cudaGetDeviceProperties(&amp;prop, i);</span><br><span class="line">        printf(&quot;Name: %s\n&quot;, prop.name);</span><br><span class="line">        printf(&quot;Total global memory: %ld\n&quot;, prop.totalGlobalMem);</span><br><span class="line">        printf(&quot;Total constant memory: %ld\n&quot;, prop.totalConstMem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在编写代码中，偶尔会需要指定CUDA设备，比如说主机和设备之间通信频繁的话，最好选用集成GPU。我们可以通过’cudaChooseDevice()’选择设备。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int main(void) &#123;</span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    int dev;</span><br><span class="line">    cudaGetDevice(&amp;dev);</span><br><span class="line">    printf(&quot;ID of current CUDA device: %d\n&quot;, dev);</span><br><span class="line">    memset(&amp;prop, 0, sizeof(cudaDeviceProp));</span><br><span class="line">    prop.major = 1;</span><br><span class="line">    prop.minor = 3;</span><br><span class="line">    cudaChooseDevice(&amp;dev, &amp;prop);</span><br><span class="line">    printf(&quot;ID of CUDA device choset to revision 1.3: %d\n&quot;, dev);</span><br><span class="line">    cudaSetDevice(dev);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="CUDA-并行编程"><a href="#CUDA-并行编程" class="headerlink" title="CUDA 并行编程"></a>CUDA 并行编程</h1><p>下面我们尝试使用并行的思想，用CUDA实现向量加法：输入两个vector，将其对应位相加的结果保存在第三个vector中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#define N 10</span><br><span class="line">int main(void) &#123;</span><br><span class="line">    int a[N], b[N], c[N];</span><br><span class="line">    int *dev_a, *dev_b, *dev_c;</span><br><span class="line"></span><br><span class="line">    // 在GPU上分配内存</span><br><span class="line">    cudaMelloc((void**)&amp;dev_a, N * sizeof(int));</span><br><span class="line">    cudaMelloc((void**)&amp;dev_b, N * sizeof(int));</span><br><span class="line">    cudaMelloc((void**)&amp;dev_c, N * sizeof(int));</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i&lt;N; i++)&#123;//在CPU上初始化三个数组</span><br><span class="line">        a[i] = -i;</span><br><span class="line">        b[i] = i * i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //将a，b两个数组复制到GPU内存上</span><br><span class="line">    cudaMemcpy(dev_a, a, N*sizeof(int), cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(dev_b, b, N*sizeof(int), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    add&lt;&lt;&lt;N, 1&gt;&gt;&gt;(dev_a, dev_b, dev_c);</span><br><span class="line"></span><br><span class="line">    //将GPU上的计算结果返回到主机中</span><br><span class="line">    cudaMemcpy(c, dev_c, N * sizeof(int), cudaMemcpyDeviceToHost)</span><br><span class="line"></span><br><span class="line">    for(int i = 0; i&lt;N; i++)&#123;</span><br><span class="line">        printf(&quot;%d + %d = %d\n&quot;, a[i], b[i], c[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaFree(dev_a);</span><br><span class="line">    cudaFree(dev_b);</span><br><span class="line">    cudaFree(dev_c);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ void add(int *a, int *b, int *c)&#123;</span><br><span class="line">    int tid = blockIdx.x;</span><br><span class="line">    if (tid &lt; N)</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里我们要说明的是，在调用设备函数add&lt;&lt;&lt;N, M&gt;&gt;&gt;时，两个参数的意义：</p>
<pre><code>1. 第一个参数表示运行时创建N个设备函数的副本并以并行的方式运行他们，我们将每个并行执行环境都称为一个线程块(block)。如果指定kernel&lt;&lt;&lt;256,1&gt;&gt;&gt;,那么将有256个线程块在GPU上运行。
2. 第二个参数表示在每个线程块中创建的线程数量M。
3. 在GPU中，一共有N*M个并行线程运行
</code></pre><h4 id="线程索引"><a href="#线程索引" class="headerlink" title="线程索引"></a>线程索引</h4><p>但在运行核函数的时候，我们往往需要知道当前的核函数是哪个block，所以在核函数中，我们看到’int tid = blockIdx.x’，blockIdx是一个内置变量，在CUDA运行时已经预先定义了这个变量。而后面的’.x’是因为CUDA支持二维线性块数组，所以有了’.x’, ‘.y’。<br>在启动核函数时，我们将并行线程块的数量指定为N，这个并行线程块集合也称为一个线程格(Grid)，这个告诉运行时，我们想要一个一维的线程格，其中包括N个线程块。每个线程块的blockIdx.x值都是不同的，第一个线程块的blockIdx.x为0，最后一个为N-1。</p>
<h4 id="线程索引优化"><a href="#线程索引优化" class="headerlink" title="线程索引优化"></a>线程索引优化</h4><p>在上一个矢量加法中，我们调用核函数’add&lt;&lt;&lt;N, 1&gt;&gt;&gt;’，表示启动N个核函数，每个核函数中有1个线程。在本章我们稍作修改，改为启动一个线程块，该线程块包含N个线程：’add&lt;&lt;&lt;1, N&gt;&gt;&gt;’，对应的，在核函数中，取线程块索引改为取线程索引：’int tid = threadIdx.x + blockIdx.x * blockDim.x’。新出现的变量blockDim保存的是线程块中每一维的线程数量，由于使用的是一维线程块，所以只用到blockDim.x。</p>
<p>两种方法都可以在GPU上启动多个线程，对比这两种方法，GPU可以一次启动65535个线程块，而一般而言，每个线程块内的最多启动512个线程，这是第一个不同。</p>
<p>而如果我们需要实现任意长度vector加法，以上的数量限制显然是不能实现的，这里我们只需要修改一下核函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__ add(int *a, int *b, int *c) &#123;</span><br><span class="line">    int tid = threadIdx.x + blockIdx.x blockDim.x;</span><br><span class="line">    while (tid &lt; N) &#123;</span><br><span class="line">        c[tid] = a[tid] + b[tid];</span><br><span class="line">        tid += gridDim.x * blockDim.x; // 每次位移一个线程grid内的所有线程数量</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>通过在循环内’tid += gridDim.x * blockDim.x’，每次可以让tid移动一个线程grid内线程数量的位移，然后再判断tid是否小于N。通过这种方法实现了计算任意长度的向量加法。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到此，我们已经学习了如何声明GPU函数，开辟GPU内存以及GPU和CPU内存之间的复制。通过两个例子也大概理解了CUDA的运行过程和工作机制，最后，我们通过优化tid的更新方式实现了任意长度向量的加法。</p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="Dongfang Li WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="Dongfang Li Alipay"/>
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/CUDA/" rel="tag"><i class="fa fa-tag"></i> CUDA</a>
          
            <a href="/tags/Parallel-Computing/" rel="tag"><i class="fa fa-tag"></i> Parallel Computing</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/11/12/CUDA/CUDA笔记（四）/" rel="next" title="CUDA 学习笔记（四）">
                <i class="fa fa-chevron-left"></i> CUDA 学习笔记（四）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/11/28/Deep Learning/TensorFlow常用函数整理/" rel="prev" title="TensorFlow常用函数整理">
                TensorFlow常用函数整理 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Dongfang Li</p>
              <p class="site-description motion-element" itemprop="description">My blog about programming and machine learning</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/YHfeather" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.facebook.com/dongfang.li.790" target="_blank" title="FB Page">
                      
                        <i class="fa fa-fw fa-facebook"></i>FB Page</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#第一个CUDA程序"><span class="nav-number">1.</span> <span class="nav-text">第一个CUDA程序</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA加法"><span class="nav-number">2.</span> <span class="nav-text">CUDA加法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#cudaMalloc-函数"><span class="nav-number">2.0.1.</span> <span class="nav-text">cudaMalloc()函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cudaMemcpy"><span class="nav-number">2.0.2.</span> <span class="nav-text">cudaMemcpy()</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#查询设备"><span class="nav-number">3.</span> <span class="nav-text">查询设备</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA-并行编程"><span class="nav-number"></span> <span class="nav-text">CUDA 并行编程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#线程索引"><span class="nav-number">0.0.1.</span> <span class="nav-text">线程索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#线程索引优化"><span class="nav-number">0.0.2.</span> <span class="nav-text">线程索引优化</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">1.</span> <span class="nav-text">总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dongfang Li</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://blackfeather.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2017/11/12/CUDA/CUDA学习笔记(一)/';
          this.page.identifier = '2017/11/12/CUDA/CUDA学习笔记(一)/';
          this.page.title = 'CUDA学习笔记(一)';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://blackfeather.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  

  

  

</body>
</html>
