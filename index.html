<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="My blog about programming and machine learning">
<meta name="keywords" content="Machine Learning, Deep Learning, TensorFlow, Python">
<meta property="og:type" content="website">
<meta property="og:title" content="Black Feather">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Black Feather">
<meta property="og:description" content="My blog about programming and machine learning">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Black Feather">
<meta name="twitter:description" content="My blog about programming and machine learning">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Black Feather</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Black Feather</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/27/自制编程语言/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/27/自制编程语言/" itemprop="url">自制编程语言</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-27T00:00:00+09:00">
                2018-07-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/07/27/自制编程语言/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/07/27/自制编程语言/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本文是通过对《2週間でできる! スクリプト言語の作り方》这本书的学习，完成一个简单的编译器。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/07/27/自制编程语言/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/21/Scheme语言基本语法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/21/Scheme语言基本语法/" itemprop="url">Scheme基本语法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-05-21T00:00:00+09:00">
                2018-05-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Programming-Language/" itemprop="url" rel="index">
                    <span itemprop="name">Programming Language</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/05/21/Scheme语言基本语法/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/05/21/Scheme语言基本语法/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>因为研究室要进行EOPL（《Essentials of Programming Languages》）的轮讲，而这本书是用Scheme作为教学语言，以至于不得不学习一下Scheme的基本语法。作为一种教学性质的函数式编程语言，Scheme语法简单，非常通俗易懂，可以帮助程序员理解函数式编程思想，还是值得一学的。而且著名的编程神书SICP（《Structure and Interpretation of Computer Programs》）也是用Scheme作为教学语言。所以为了方便更好的理解这两本书，对Scheme的基本语法有一个简单的了解还是有必要的。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/05/21/Scheme语言基本语法/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/27/SICP第二章笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/27/SICP第二章笔记/" itemprop="url">SICP第二章:构造数据抽象</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-27T00:00:00+09:00">
                2018-04-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Programming-Language/" itemprop="url" rel="index">
                    <span itemprop="name">Programming Language</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/27/SICP第二章笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/04/27/SICP第二章笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>让我们进入SICP的第二章：构造数据抽象<br>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/04/27/SICP第二章笔记/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/21/各种Boosting树/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/21/各种Boosting树/" itemprop="url">各种boosting树</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-21T00:00:00+09:00">
                2018-04-21
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/21/各种Boosting树/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/04/21/各种Boosting树/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p>Gradient Boosting是一种Boosting的方法，它主要的思想是，每一次建立模型是在之前建立模型损失函数的梯度下降方向。损失函数是评价模型性能（一般为拟合程度+正则项），认为损失函数越小，性能越好。而让损失函数持续下降，就能使得模型不断改性提升性能，其最好的方法就是使损失函数沿着梯度方向下降（讲道理梯度方向上下降最快）。</p>
<p>Gradient Boost是一个框架，里面可以套入很多不同的算法。</p>
<p>主要由三个概念组成：回归决策树，Gradient Boosting，Shrinkage。</p>
<h4 id="回归决策树"><a href="#回归决策树" class="headerlink" title="回归决策树"></a>回归决策树</h4><p>GBDT的核心在于累加所有树的结果作为最终结果，而 <strong>分类树的结果累加是没有意义的， 所以GBDT中的树都是回归树，不是分类树</strong>。<br>GBDT调整后可以用于分类问题，但内部还是回归树。<br><strong>回归树在每个节点（不一定是叶子节点）都会得到一个预测值。</strong> 以年龄为例，该预测值等于属于这个节点所有人年龄的平均值，分枝时穷举每一个feature的每一个阈值找到最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差。</p>
<h4 id="梯度迭代"><a href="#梯度迭代" class="headerlink" title="梯度迭代"></a>梯度迭代</h4><p><img src="other_ML_knowledge/gbdt_alg.png" alt="GBDT"><br>GBDT学习过程如上图所示，主要流程是：</p>
<ol>
<li>初始化f0(x) = 0</li>
<li>对于m=1,2,..M<ol>
<li>计算后之前所有树的残差</li>
<li>拟合残差学习一颗回归树 （李红损失函数的负梯度在当前模型的值作为残差近似值）</li>
<li>更新回归树集合（进行相加时通常会使用Shrinkage）</li>
</ol>
</li>
<li>M次迭代后，得到GBDT模型，为M个回归树的加性模型</li>
</ol>
<p>还是以预测年龄为例，GBDT是把所有树的结论累加起来做最终结论的，所以可以想到每棵树的结论并不是年龄本身，而是年龄的一个累加量。 <strong>GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。</strong><br>比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是Gradient Boosting在GBDT中的意义。<br><strong>Gradient 体现在：无论前面一颗树的 cost function 是什么，是均方差还是均差，只要它以误差作为衡量标准，那么残差向量都是它的全局最优方向，这就是 Gradient。</strong></p>
<h4 id="GBDT数学原理"><a href="#GBDT数学原理" class="headerlink" title="GBDT数学原理"></a>GBDT数学原理</h4><p><img src="images/other_ML_knowledge/gbdt_math2.png" alt="gbdt_math2"><br><img src="images/other_ML_knowledge/gbdt_math.png" alt="gbdt_math"><br>从数学的角度，GBDT是对目标函数的负梯度进行拟合，而当我们计算负梯度时，会发现它正好等于残差。</p>
<h4 id="GBDT-工作实例"><a href="#GBDT-工作实例" class="headerlink" title="GBDT 工作实例"></a>GBDT 工作实例</h4><p>还是年龄预测，简单起见训练集只有4个人，A,B,C,D，他们的年龄分别是14,16,24,26。其中A、B分别是高一和高三学生；C,D分别是应届毕业生和工作两年的员工。如果是用一棵传统的回归决策树来训练，会得到如下所示结果：<br><img src="images/other_ML_knowledge/decision_tree.jpg" alt="decision_tree"><br>现在我们使用GBDT来做这件事，由于数据太少，我们限定叶子节点最多有两个，即每棵树都只有一个分枝，并且限定只学两棵树。我们会得到如下图2所示结果：<br><img src="images/other_ML_knowledge/boosting_tree.jpg" alt="decision_tree"><br>在GBDT的第一棵树中，(A,B)和(C,D)被分为两拨，每拨用平均年龄作为预测值。此时计算残差（残差的意思就是： A的预测值 + A的残差 = A的实际值），所以A的残差就是16-15=1（注意，A的预测值是指前面所有树累加的和，这里前面只有一棵树所以直接是15，如果还有树则需要都累加起来作为A的预测值）。进而得到A,B,C,D的残差分别为-1,1，-1,1。然后我们拿残差替代A,B,C,D的原值，到第二棵树去学习，如果我们的预测值和它们的残差相等，则只需把第二棵树的结论累加到第一棵树上就能得到真实年龄了。这里直接分成两个节点。此时所有人的残差都是0，即每个人都得到了真实的预测值。</p>
<p>换句话说，现在A,B,C,D的预测值都和真实年龄一致了。</p>
<p>A: 14岁高一学生，购物较少，经常问学长问题；预测年龄A = 15 – 1 = 14</p>
<p>B: 16岁高三学生；购物较少，经常被学弟问问题；预测年龄B = 15 + 1 = 16</p>
<p>C: 24岁应届毕业生；购物较多，经常问师兄问题；预测年龄C = 25 – 1 = 24</p>
<p>D: 26岁工作两年员工；购物较多，经常被师弟问问题；预测年龄D = 25 + 1 = 26</p>
<p><strong>Gradient在哪里？其实回到第一棵树结束，无论此时的cost function是什么，是均方差还是均差，只要它以误差作为衡量标准，残差向量(-1, 1, -1, 1)都是它的全局最优方向，这就是Gradient。</strong></p>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><ol>
<li>既然图1和图2 最终效果相同，为何还需要GBDT呢？<br>答案是过拟合。</li>
</ol>
<p>我们发现图1为了达到100%精度使用了3个feature（上网时长、时段、网购金额），其中分枝“上网时长&gt;1.1h” 很显然已经过拟合了，这个数据集上A,B也许恰好A每天上网1.09h, B上网1.05小时，但用上网时间是不是&gt;1.1小时来判断所有人的年龄很显然是有悖常识的；</p>
<p>相对来说图2的boosting虽然用了两棵树 ，但其实只用了2个feature就搞定了，后一个feature是问答比例，显然图2的依据更靠谱。 <strong>Boosting的最大好处在于，每一步的残差计算其实变相地增大了分错instance的权重，而已经分对的instance则都趋向于0。这样后面的树就能越来越专注那些前面被分错的instance。</strong></p>
<ol start="2">
<li>Gradient呢？不是“G”BDT么？<br>到目前为止，我们的确没有用到求导的Gradient。在当前版本GBDT描述中，的确没有用到Gradient，该版本用残差作为全局最优的绝对方向，并不需要Gradient求解.</li>
</ol>
<h4 id="Shrinkage"><a href="#Shrinkage" class="headerlink" title="Shrinkage"></a>Shrinkage</h4><p>Shrinkage（缩减）的思想认为，每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。用方程来看更清晰，即</p>
<p>没用Shrinkage时：（yi表示第i棵树上y的预测值， y(1~i)表示前i棵树y的综合预测值）</p>
<p>y(i+1) = 残差(y1~yi)， 其中： 残差(y1~yi) =  y真实值 - y(1 ~ i)</p>
<p>y(1 ~ i) = SUM(y1, …, yi)</p>
<p>Shrinkage不改变第一个方程，只把第二个方程改为：</p>
<p>y(1 ~ i) = y(1 ~ i-1) + step * yi</p>
<p><strong>即Shrinkage仍然以残差作为学习目标，但对于残差学习出来的结果，只累加一小部分（step*残差）逐步逼近目标，step一般都比较小，如0.01~0.001（注意该step非gradient的step），导致各个树的残差是渐变的而不是陡变的。直觉上这也很好理解，不像直接用残差一步修复误差，而是只修复一点点，其实就是把大步切成了很多小步。本质上，Shrinkage为每棵树设置了一个weight，累加时要乘以这个weight</strong>。就像Adaboost一样，Shrinkage能减少过拟合发生也是经验证明的，目前还没有看到从理论的证明。</p>
<h4 id="GBDT的适用范围"><a href="#GBDT的适用范围" class="headerlink" title="GBDT的适用范围"></a>GBDT的适用范围</h4><ul>
<li>GBDT 可以适用于回归问题（线性和非线性）；</li>
<li>GBDT 也可用于二分类问题（设定阈值，大于为正，否则为负）和多分类问题。<h4 id="GBDT和随机森林的异同点"><a href="#GBDT和随机森林的异同点" class="headerlink" title="GBDT和随机森林的异同点"></a>GBDT和随机森林的异同点</h4></li>
<li>都是由多棵树组成；</li>
<li>最终的结果都由多棵树共同决定。</li>
<li>GBDT 和随机森林的不同点：</li>
<li>组成随机森林的可以是分类树、回归树；组成 GBDT 只能是回归树；</li>
<li>组成随机森林的树可以并行生成（Bagging）；GBDT 只能串行生成（Boosting）；这两种模型都用到了Bootstrap的思想。</li>
<li>对于最终的输出结果而言，随机森林使用多数投票或者简单平均；而 GBDT 则是将所有结果累加起来，或者加权累加起来；</li>
<li>随机森林对异常值不敏感，GBDT 对异常值非常敏感；</li>
<li>随机森林对训练集一视同仁权值一样，GBDT 是基于权值的弱分类器的集成；</li>
<li>随机森林通过减小模型的方差提高性能，GBDT 通过减少模型偏差提高性能。<h4 id="GBDT相比于决策树的优点"><a href="#GBDT相比于决策树的优点" class="headerlink" title="GBDT相比于决策树的优点"></a>GBDT相比于决策树的优点</h4></li>
</ul>
<ol>
<li>GBDT 相比于决策树有什么优点</li>
</ol>
<p>泛化性能更好！GBDT 的最大好处在于，每一步的残差计算其实变相的增大了分错样本的权重，而已经分对的样本则都趋向于 0。这样后面就更加专注于那些分错的样本。</p>
<ol start="2">
<li>Gradient 体现在哪里？</li>
</ol>
<p>可以理解为残差是全局最优的绝对方向，类似于求梯度。</p>
<ol start="3">
<li>re-sample</li>
</ol>
<p>GBDT 也可以在使用残差的同时引入 Bootstrap re-sampling，GBDT 多数实现版本中引入了这个选项，但是是否一定使用有不同的看法。</p>
<p>原因在于 re-sample 导致的随机性，使得模型不可复现，对于评估提出一定的挑战，比如很难确定性能的提升是由于 feature 的原因还是 sample 的随机因素。</p>
<h2 id="xgboost"><a href="#xgboost" class="headerlink" title="xgboost"></a>xgboost</h2><p>目前最好最快的boosting tree</p>
<p>如果不考虑工程实现、解决问题上的一些差异，xgboost与gbdt比较大的不同就是目标函数的定义。<br><img src="images/other_ML_knowledge/xgboost_fomula.jpy" alt="xgboost_fomula"><br>注：红色箭头指向的l即为损失函数；红色方框为正则项，包括L1、L2；红色圆圈为常数项。xgboost利用泰勒展开三项，做一个近似，我们可以很清晰地看到，最终的目标函数只依赖于每个数据点的在误差函数上的一阶导数和二阶导数。</p>
<h4 id="原理详解"><a href="#原理详解" class="headerlink" title="原理详解"></a>原理详解</h4><p><img src="images/other_ML_knowledge/xgboost_math1.jpg" alt="gbdt_math"><br>对GBDT的目标函数（平方损失）进行泰勒2阶展开，得到如上图推导过程。<br><img src="images/other_ML_knowledge/xgboost_math2.png" alt="gbdt_math2"></p>
<p>推导上述目标函数公式后，可以进行单棵决策树的学习：</p>
<ol>
<li>枚举所有可能的树结构q</li>
<li>用上述目标函数为每个q计算目标函数分数，分数越小说明对应的树结构越好</li>
<li>根据上一步的结果，找到最佳树结构，并计算每个叶节点的预测值wj</li>
</ol>
<h4 id="xgboost对比GBDT"><a href="#xgboost对比GBDT" class="headerlink" title="xgboost对比GBDT"></a>xgboost对比GBDT</h4><ol>
<li>GBDT缺点明显：boost是一个串行过程，不好并行化，计算复杂度高，传统GBDT在优化时只用到了一阶导数信息</li>
<li>XGB显式吧树模型复杂度作为了正则项，数据事先排序并且以 block 形式存储，有利于并行计算。</li>
<li>原始GBDT是再拟合负梯度，XGB是二姐展开直接求解析解，然后得到gain公式，贪心构造树。</li>
<li>加入正则项，防止过拟合。</li>
<li>GBDT是直接拟合负梯度（等于残差），xgboost对目标函数进行泰勒展开，引入二阶导。</li>
</ol>
<h4 id="GBDT和xgboost的异同"><a href="#GBDT和xgboost的异同" class="headerlink" title="GBDT和xgboost的异同"></a>GBDT和xgboost的异同</h4><p>传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。<br>传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。顺便提一下，xgboost工具支持自定义代价函数，只要函数可一阶和二阶求导。<br>xgboost在代价函数里加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、每个叶子节点上输出的score的L2模的平方和。从Bias-variance tradeoff角度来讲，正则项降低了模型的variance，使学习出来的模型更加简单，防止过拟合，这也是xgboost优于传统GBDT的一个特性。<br>Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率）<br>列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。<br>可并行的近似直方图算法。树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点。</p>
<p>xgboost工具支持并行。boosting不是一种串行的结构吗?怎么并行的？注意xgboost的并行不是tree粒度的并行，xgboost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值）。xgboost的并行是在特征粒度上的。我们知道，决策树的学习最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点），xgboost在训练之前，预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个block结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
<h2 id="lightgbm"><a href="#lightgbm" class="headerlink" title="lightgbm"></a>lightgbm</h2><p>GBDT 虽然是个强力的模型，但却有着一个致命的缺陷，不能用类似 mini batch 的方式来训练，需要对数据进行无数次的遍历。如果想要速度，就需要把数据都预加载在内存中，但这样数据就会受限于内存的大小；如果想要训练更多的数据，就要使用外存版本的决策树算法。虽然外存算法也有较多优化，SSD 也在普及，但在频繁的 IO 下，速度还是比较慢的。为了能让 GBDT 高效地用上更多的数据，我们把思路转向了分布式 GBDT， 然后就有了 LightGBM。设计的思路主要是两点，1. 单个机器在不牺牲速度的情况下，尽可能多地用上更多的数据；2.多机并行的时候，通信的代价尽可能地低，并且在计算上可以做到线性加速。</p>
<ol>
<li>histogram决策树算法替换了传统的Pre-Sorted，histogram在内存消耗和计算代价上优势不小</li>
<li>带有深度限制的按叶子生长算法代替了传统的决策树生长策略，提升精度同时避免过拟合。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/18/Hadoop入门/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/18/Hadoop入门/" itemprop="url">Hadoop入门</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-18T00:00:00+09:00">
                2018-04-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data/" itemprop="url" rel="index">
                    <span itemprop="name">Big Data</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/18/Hadoop入门/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/04/18/Hadoop入门/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>Hadoop如今已经成为了大数据处理的代名词，无论是云计算，机器学习还是后端开发都离不开大数据的支持，这篇文章就是我整理的关于Hadoop的入门概念。<br>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/04/18/Hadoop入门/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/16/sklearn学习笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/16/sklearn学习笔记/" itemprop="url">sklearn学习笔记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-16T00:00:00+09:00">
                2018-04-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/16/sklearn学习笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/04/16/sklearn学习笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>Sklearn是机器学习领域最知名的python模块之一，广泛的应用到各种机器学习项目中。Sklearn使用方便，大多数ML算法的调用形式相同，极其易于入门。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/04/16/sklearn学习笔记/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/Python装饰器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/12/Python装饰器/" itemprop="url">python装饰器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-12T00:00:00+09:00">
                2018-04-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Programming-Language/" itemprop="url" rel="index">
                    <span itemprop="name">Programming Language</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/12/Python装饰器/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/04/12/Python装饰器/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>python装饰器类似于java中的面向切面编程，是python的高级语法， 可以将各个函数中重复的操作（插入日志，性能测试，事务处理，缓存等）抽离出来，将这些于函数原本功能无关的雷同代码定义在装饰器中，概括的讲： <strong>装饰器的作用就是为已经存在的对象添加额外的功能</strong><br>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/04/12/Python装饰器/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/11/机器学习西瓜书知识点整理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/11/机器学习西瓜书知识点整理/" itemprop="url">机器学习西瓜书知识点整理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-11T00:00:00+09:00">
                2018-04-11
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/11/机器学习西瓜书知识点整理/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/04/11/机器学习西瓜书知识点整理/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章 模型评估与选择"></a>第二章 模型评估与选择</h1><ul>
<li>学习器在训练集上的误差称为训练误差或者经验误差，在新样本上的误差称为泛华误差<h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2></li>
<li>留出法：直接将数据集分为两个不相交的子集，一个训练，一个测试。一般需要多次划分对评估结果取平均值。</li>
<li>交叉验证：将数据集分成k个大小相同的子集，每次用一个子集i作为测试，用剩下的k-1作为训练，然后遍历k个子集会产生k个训练/测试结果。留一法：让k=数据集大小，也就是说每次直选一个样本进行测试。</li>
<li>自助法：有放回的从原始数据集采样，每次取一个数据复制放入新数据集，然后将该数据放回，重复采样直到新数据集大小为m，初始数据集中会有36%的样本未出现在新数据集中，用新数据训练，用未出现的数据集做测试。<ol>
<li>自助法在数据集小，难以有效划分时有用，但改变了初始数据集的分布，引入了估计偏差。</li>
</ol>
</li>
</ul>
<h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><ul>
<li>错误率和精度</li>
<li>查准率，查全率，F1值</li>
<li>P-R曲线（查准率，查全率曲线）<ol>
<li>将预测结果从最可能到最不可能进行排序，按照此顺序逐个把样本作为正例进行预测，并记录每一刻的P-R值</li>
<li>可以比较PR曲线下的面积来比较模型性能，或者比较平衡点（P==R）的大小</li>
<li>可以根据不同任务需求采用不同的截断点，更重视P则选择排序靠前的位置截断。。。</li>
</ol>
</li>
<li>ROC曲线&amp;AUC<ul>
<li>同样将样本从可能正例到不可能正例排序，首先个将所有样例均预测为反例，这时真正例率和假正例率都为0，然后调整阈值，依次将每个样例划分为正例。每次计算真正例率和假正例率绘制ROC曲线</li>
<li>真正例率：所有真实正例中被预测为正例的比例（对正例预测正确）</li>
<li>假正例率：所有真实反例中被预测为正例的比例（对反例预测错误）</li>
<li>RUC考虑的事样本预测的排序质量，因此它与排序误差有紧密联系</li>
<li>ROC曲线下方围成的面积即为AUC</li>
<li>因为AUC为点连成的非光滑曲线，所以可以通过计算各个相邻点组成的小矩形面积之和得出AUC</li>
</ul>
</li>
</ul>
<ol start="5">
<li>代价敏感误差率与代价曲线<ul>
<li>构建有代价权重的混淆矩阵，然后可以依据此计算表示代价的ROC曲线</li>
</ul>
</li>
</ol>
<h2 id="比较检验"><a href="#比较检验" class="headerlink" title="比较检验"></a>比较检验</h2><ol>
<li>假设检验</li>
<li>交叉验证t检验</li>
<li>McNemar检验from</li>
<li>Friedman检验和Nemenyi后续检验</li>
<li>偏差和方差</li>
</ol>
<h1 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h1><h2 id="最小二乘法和其矩阵形式"><a href="#最小二乘法和其矩阵形式" class="headerlink" title="最小二乘法和其矩阵形式"></a>最小二乘法和其矩阵形式</h2><pre><code>1. 基于均方误差最小化来进行模型求解的方法称为最小二乘法
2. 在线性回归模型中最小二乘法就是试图找到一条直线，使所有样本到直线的欧式距离之和最小
3. 最小二乘法即对每个参数求偏导，并令其等于0.
4. 最小二乘法的矩阵表示和解法（原理相同，只是变为对矩阵求偏导）
5. **对数线性回归** 实质上已是在求输入空间到输出空间的非线性函数映射：ln(y) = wx + b
6. **广义线性模型** y = g-1(wx + b)
</code></pre><h2 id="逻辑斯蒂回归"><a href="#逻辑斯蒂回归" class="headerlink" title="逻辑斯蒂回归"></a>逻辑斯蒂回归</h2><ul>
<li>优点：实现简单，分类时计算量非常小，速度快，存储资源低</li>
<li>缺点：容易欠拟合，准确度不高。只能处理二分类问题（衍生的softmax可解决），样本必须线性可分。<h4 id="LR推导"><a href="#LR推导" class="headerlink" title="LR推导"></a>LR推导</h4>掌握<h4 id="几率和对数几率"><a href="#几率和对数几率" class="headerlink" title="几率和对数几率"></a>几率和对数几率</h4><ol>
<li>y/(1-y)称为几率，反映了样本作为正例的相对可能性。对几率取对数为对数几率</li>
<li>ln(y/(1-y)) = wx + b 等价于 y = 1/(1+exp(-wx-b))</li>
<li>由上式可看出，LR本质上是训练一个线性模型，逼近真是label的对数几率，也就是数据作为正例的相对可能性。</li>
</ol>
</li>
</ul>
<h2 id="线性判别分析（LDA）"><a href="#线性判别分析（LDA）" class="headerlink" title="线性判别分析（LDA）"></a>线性判别分析（LDA）</h2><ul>
<li>书第60页<br>LDA思想：给定训练数据集，设法将样例投影到一条直线上，是的同类样例的投影点尽可能接近，异类样例的投影点尽可能远离。<strong>衡量同类样例距离尽可能小只需要让协方差尽可能小，异类样例距离尽可能大只需要让类中心之间的距离尽可能大。</strong><br>在对新样例进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来判断新样本的类别。</li>
</ul>
<h2 id="3-5-多分类学习"><a href="#3-5-多分类学习" class="headerlink" title="3.5 多分类学习"></a>3.5 多分类学习</h2><p>多分类学习的基本思路是“拆解法”，即将多个分类任务拆为若干个二分类任务求解。经典的拆分策略有三种：‘一对一’，‘一对余’，‘多对多’</p>
<ol>
<li>一对一OvO：将N个类别两两配对，产生N*(N-1)/2个二分类任务。在 <strong>测试阶段</strong> ，新样本将同时提交给所有分类器，于是我们得到N(N-1)/2个分类结果，最终结果可以通过投票产生，即把被预测最多的类别作为最终分类结果。</li>
<li>一对余OvR：每次将一个类作为正例，剩下的N-1个类作为反例来训练N个分类器。在 <strong>测试阶段</strong> 若仅有一个分类器预测为正例，则对应的类别标记作为最终分类结果。若有多个分类器预测为正例，则通常考虑各个分类器的预测置信度，选择置信度最大的类别标记为分类结果。</li>
<li>多对多MvM：每次将若干类作为正类，若干类其他类作为反类，显然OvO和OvM是MvM的特例。MvM正反类的构造必须有特殊的设计，不能随意选取，通常使用“纠错输出码（ECOC）”技术。<ul>
<li>ECOE技术详见书第65页</li>
</ul>
</li>
</ol>
<h2 id="3-6-类别不平衡问题"><a href="#3-6-类别不平衡问题" class="headerlink" title="3.6 类别不平衡问题"></a>3.6 类别不平衡问题</h2><ol>
<li>对于线性分类y=wx+b, 我们通常认为y&gt;0.5为正例y&lt;0.5为反例，说明几率y/(1-y)的阈值为0.5，表示分类器认为正反例可能性相同。所以我们只需要修改分类器预测几率的阈值即可：若y/(1-y) &gt; m+/m-则判定为正例。</li>
<li>解决类别不平衡学习的一个基本策略：<strong>再缩放</strong>，对预测出的几率乘以正负例的比值即为模型的预测输出。</li>
<li>实际应用中共有三种做法： <strong>欠采样，过采样，阈值移动</strong><ul>
<li>欠采样即去除一些反例使得正反例数目接近，由于欠采样可能丢失重要信息，实践中使用EasyEnsemble利用集成学习将反例划分为若干个集合供不同学习器使用，这样对于每个学习器来说都是欠采样，但在全局看来不会丢失信息。</li>
<li>过采样即增加一些正例使得正反例数目接近（不能简单地对正例进行重复否则会产生严重的过拟合，SMOTE算法通过对训练集里的正例进行插值来产生额外的正例。</li>
<li>阈值移动即为开始所述，对预测几率乘以正反例数量的比值</li>
</ul>
</li>
</ol>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="为什么不直接对loss-function求偏导-0，而要用梯度下降？"><a href="#为什么不直接对loss-function求偏导-0，而要用梯度下降？" class="headerlink" title="为什么不直接对loss function求偏导=0，而要用梯度下降？"></a>为什么不直接对loss function求偏导=0，而要用梯度下降？</h3><ol>
<li>逻辑回归没有解析解，就是说无法显式的表现函数的偏导，只能通过数值求解的方法迭代地找到最优解。</li>
<li>即使有解析解，大部分神经网络的loss为非凸函数，KKT条件（偏导为0是其中一项）仅仅是非凸函数最优化的必要非充分条件。</li>
<li>偏导为0可能并非是局部极值</li>
</ol>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><ul>
<li>优点：计算量小，可解释性强，比较适合处理有缺失值的样本，能够处理不相关特征</li>
<li>容易过拟合（集成树方法减少了过拟合现象）<h2 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h2><h4 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h4>信息熵值越小，纯度越高。<h4 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h4></li>
<li>一般而言，信息增益越大，意味着使用属性a来进行划分所获得的“纯度提升”越大。</li>
<li>缺点：信息增益倾向于选择可取值数目较多的属性。<h4 id="增益率"><a href="#增益率" class="headerlink" title="增益率"></a>增益率</h4></li>
<li>增益率为：信息增益/分割属性的信息熵</li>
<li>缺点：增益率倾向于选择取值数目较少的属性<h4 id="ID3决策树算法"><a href="#ID3决策树算法" class="headerlink" title="ID3决策树算法"></a>ID3决策树算法</h4></li>
</ul>
<ol>
<li>ID3决策树生成算法采用信息增益生成决策树（见P75）</li>
<li>基于信息增益的划分法会偏向选取取值多的属性（如果用ID进行划分，也就是每个分治只有一个样本，每个分治纯度最大，但这样显然不具备泛化能力）<h4 id="ID4-5决策树算法"><a href="#ID4-5决策树算法" class="headerlink" title="ID4.5决策树算法"></a>ID4.5决策树算法</h4></li>
<li>为克服基于信息增益的算法偏向选择属性多的缺点，ID4.5基于信息增益率生成决策树</li>
<li>信息增益率即： （属性A的信息增益）/（属性A的信息熵）</li>
<li>增益率准则倾向选择取值少的属性，因此C4.5算法并不是简单选用增益率划分，而是使用了一个启发式方法：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。<h4 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a>基尼系数</h4></li>
</ol>
<ul>
<li>CART树使用基尼系数进行属性划分</li>
<li>如果是二分类问题，基尼系数为：Gini(p) = 2p(1-p)</li>
<li>直观来说，基尼系数反应了从数据集随机抽取两个样本，其类别标记不一致的概率，因此Gini系数越小，数据集的纯度越高。</li>
</ul>
<h2 id="决策树剪枝"><a href="#决策树剪枝" class="headerlink" title="决策树剪枝"></a>决策树剪枝</h2><ul>
<li>决策树剪枝的基本策略有“预剪枝”和“后剪枝”。<h4 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h4><ol>
<li>预剪枝是指在决策树生成过程中，对每个节点在划分前先进行估计，若当前节点的划分不能带来决策树泛华性能的提升，则停止划分并将当前节点标记为叶节点；首先单独分出一个测试集，然后分别测试当前节点不分裂，和节点分裂后的分类准确率，如果节点分裂后的准确率更高，则进行划分。 <strong>比较划分前后在验证集的精度是否提高</strong></li>
<li>预剪枝有欠拟合风险<h4 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h4></li>
<li>后剪枝则是先训练一颗完整的决策树，然后自底向上的对非叶节点进行考察，若将该节点对应的子节点替换为叶节点能带来决策树泛化性能的提升，则将该子树替换为叶节点。对于一棵训练好的决策树，自底向上分别考察每个非叶节点，并分别计算保留该节点领衔的叶节点时决策树在测试集的准确率，和将该节点的叶节点进行剪除后决策树在测试集的准确率。如果剪除该节点（将该节点的叶节点向上回滚，该节点作为叶节点）的准确率大于保留该节点，则剪除该节点。  <strong>比较划分前后在验证集的精度是否提高</strong></li>
<li>后剪枝也可以通过构建决策树loss function，最小化loss实现。</li>
<li>后剪枝欠拟合风险小，泛化性能优于预剪枝，但需要先生成再剪枝，开销大。</li>
</ol>
</li>
</ul>
<h2 id="连续值和缺失值"><a href="#连续值和缺失值" class="headerlink" title="连续值和缺失值"></a>连续值和缺失值</h2><h4 id="连续值"><a href="#连续值" class="headerlink" title="连续值"></a>连续值</h4><ul>
<li>对于取值为连续值的属性，考察该属性的所有取值，并从小到大排列。分别以任意相邻的取值的中值作为分割点，计算信息增益，并选取信息增益最大的点作为分割点。（其中可以将原节点的信息熵改为期望，因为每个取值的概率都为1/n） （具体公式见书84页）</li>
<li>与离散属性不同，若当前节点划分属性为连续属性，该属性还可作为其后代节点的划分属性。<h4 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h4>两种情况：</li>
</ul>
<ol>
<li>如何在属性值缺失的情况下进行划分属性的选择（如何重构信息增益）</li>
<li>给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分。</li>
</ol>
<h2 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h2><ul>
<li>通常决策树相当于用多个平行于轴线的线段对特征空间进行分割。这样的分类边界使得学习结果具有较好的可解释性，因为每一段划分都直接对应了某个属性的取值，<strong>但在分类边界比较复杂时，对于同一个属性，必须使用很多段划分才能获得较好的近似，此时决策树会相当复杂</strong>。</li>
<li><strong>若能使用斜的划分边界，则决策树模型会大大简化</strong>，“多变量决策树” 就是能实现这样斜划分甚至更复杂划分的决策树。</li>
<li>以斜划分为例，在此类决策树中，<strong>非节点不再是仅针对某个属性，而是对属性的线性组合进行测试，换言之，每个非叶节点是一个形如 wa=t 的线性分类器，w表示属性a的权重，w和t可以在节点所含的样本集和属性集上学得</strong></li>
<li>于是，与传统的单变量决策树不同，在多变量决策树的学习过程中，不是为每个节点寻找一个最优划分属性，而是试图建立一个合适的线性分类器。</li>
</ul>
<h2 id="CART树"><a href="#CART树" class="headerlink" title="CART树"></a>CART树</h2><h2 id="决策树用于回归"><a href="#决策树用于回归" class="headerlink" title="决策树用于回归"></a>决策树用于回归</h2><h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><h2 id="梯度下降算法推导"><a href="#梯度下降算法推导" class="headerlink" title="梯度下降算法推导"></a>梯度下降算法推导</h2><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><ul>
<li>优点：<ol>
<li>可用于线性/非线性分类，也可以用于回归</li>
<li>泛化误差较低</li>
<li>容易解释</li>
<li>计算复杂度较低</li>
</ol>
</li>
<li>缺点：<ol>
<li>对参数和核函数的选择比较敏感</li>
<li>原始的SVM只比较擅长处理二分类问题</li>
</ol>
</li>
</ul>
<h2 id="传统支持向量机"><a href="#传统支持向量机" class="headerlink" title="传统支持向量机"></a>传统支持向量机</h2><p>距离超平面最近的几个训练样本点使距离等式成立，这几个样本点称为支持向量。两个异类支持向量到超平面的距离之和称为“间隔”。</p>
<h2 id="支持向量机对偶形式"><a href="#支持向量机对偶形式" class="headerlink" title="支持向量机对偶形式"></a>支持向量机对偶形式</h2><h4 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h4><p>掌握</p>
<h4 id="KKT条件"><a href="#KKT条件" class="headerlink" title="KKT条件"></a>KKT条件</h4><h4 id="SMO算法"><a href="#SMO算法" class="headerlink" title="SMO算法"></a>SMO算法</h4><p>SMO的基本思路是先固定ai之外的所有参数，然后求ai上的机制，由于存在约束sum(aiyi)=0，若固定ai之外的其他变量则ai可以由其他变量导出。于是SMO每次选择两个变量ai，aj。并固定其他参数，这样在参数初始化后，SMO不断执行如下两个步骤直至收敛：</p>
<pre><code>1. 选取一对需要更新的变量ai和aj
2. 固定剩余的参数，求解SVM对偶式的公式获得更新后的ai和aj
</code></pre><p>注意到只要ai和aj有一个不满足KKT条件，目标函数就会在迭代后增大，KKT条件违背程度越大，变量更新后可能导致的目标函数值增幅越大。<br>于是SMO先选取违背KKT条件程度最大的变量，第二个选取使目标函数值增幅最快的变量，但比较变量复杂度过大，SMO采用启发式方法：选取两个变量所对应样本之间的间隔最大，这样的两个变量有很大差别，对目标函数的更新有更大帮助。<br>SMO每次选取两个变量优化对偶公式时，会发现该公式具有闭式解，不必用数值优化方法即可高效计算出更新后的ai，aj。</p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>可将样本从原始空间映射到一个高维看空间，使得样本在这个高维空间线性可分。如果原始空间是有限维，即属性有限，那么一定存在一个高维空间使样本可分。<br>我们发现SVM的对偶式中包含xi和xj的内积运算，使用映射方法只需要将原始空间内的内积运算转换为高维映射空间内的映射运算即可。但映射空间往往维度过高，计算复杂，所以假设存在核函数k(xi, xj) = xi,xj的內积，有了这个核函数在对偶式中只需将內积替换成核函数即可。</p>
<h4 id="核函数条件"><a href="#核函数条件" class="headerlink" title="核函数条件"></a>核函数条件</h4><p>只要一个对称函数所对应的和矩阵半正定，它就能作为核函数使用。</p>
<h4 id="核函数的种类"><a href="#核函数的种类" class="headerlink" title="核函数的种类"></a>核函数的种类</h4><p>核函数选择成了SVM的最大变数，若核函数不适合，样本被映射到了一个不适合的空间，会导致性能不佳。<br>常见的核函数有：</p>
<ol>
<li>线性核</li>
<li>多项式核</li>
<li>高斯核</li>
<li>拉普拉斯核</li>
<li>Sigmoid核<br>此外，还可以通过函数线性组合得到新的核函数。</li>
</ol>
<h2 id="软间隔支持向量机"><a href="#软间隔支持向量机" class="headerlink" title="软间隔支持向量机"></a>软间隔支持向量机</h2><p>在现实任务中我们很难恰到好处的找个某个核函数使得训练集在特征空间线性可分，也很难推是否是由过拟合造成的。所以我们允许SVM在一些样本上出错，引入软间隔概念。同时引入松弛变量的概念。</p>
<h4 id="软间隔SVM推导"><a href="#软间隔SVM推导" class="headerlink" title="软间隔SVM推导"></a>软间隔SVM推导</h4><p>掌握（软间隔的对偶形式和硬间隔的对偶形式唯一区别在于对ai的约束，软间隔的约束为’0&lt;=ai&lt;=C’, 硬间隔的约束仅为’0&lt;=ai’</p>
<h4 id="软间隔SVM的KKT条件"><a href="#软间隔SVM的KKT条件" class="headerlink" title="软间隔SVM的KKT条件"></a>软间隔SVM的KKT条件</h4><p>理解</p>
<h4 id="SVM优缺点"><a href="#SVM优缺点" class="headerlink" title="SVM优缺点"></a>SVM优缺点</h4><ul>
<li>时空开销比较大，训练时间长</li>
<li>核函数的选取比较难，主要靠经验。</li>
<li>在小训练集上往往得到比较好的结果；</li>
<li>使用核函数避开了高纬空间的复杂性；</li>
<li>泛化能力强。<h3 id="SVM和LR的异同"><a href="#SVM和LR的异同" class="headerlink" title="SVM和LR的异同"></a>SVM和LR的异同</h3></li>
</ul>
<ol>
<li>两者都为线性模型</li>
<li>两者都是判别模型</li>
<li>本质上来讲是损失函数的不同，LR为交叉熵损失（对数损失），SVM为hinge损失</li>
<li>由于损失函数不同，LR直接依赖所有数据分布，SVM只关心支持向量</li>
<li>SVM依赖距离测度，需要正则化，LR不受影响</li>
<li>SVM自带正则项，LR需要在Loss Function上添加。</li>
</ol>
<h2 id="支持向量回归"><a href="#支持向量回归" class="headerlink" title="支持向量回归"></a>支持向量回归</h2><p>对于传统回归模型通常直接计算模型输出和真实输出之间的差别来计算损失，只有当两个输出完全相同时loss才为0。SVR容忍预测和label之间最多有e的偏差，即当f预测和label之间的差别大于e才计算损失。相当于以f为中心，构建了一个宽度为2e的间隔带，样本落入该间隔带则被认为是分类正确的。</p>
<h4 id="SVR公式推导"><a href="#SVR公式推导" class="headerlink" title="SVR公式推导"></a>SVR公式推导</h4><p>掌握</p>
<h1 id="贝叶斯方法"><a href="#贝叶斯方法" class="headerlink" title="贝叶斯方法"></a>贝叶斯方法</h1><h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>掌握</p>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>公式，多个概率概念掌握</p>
<h4 id="朴素贝叶斯处理连续属性"><a href="#朴素贝叶斯处理连续属性" class="headerlink" title="朴素贝叶斯处理连续属性"></a>朴素贝叶斯处理连续属性</h4><p>对于连续属性可以考虑概率密度函数，假定该属性遵循正太分布，由此得出连续属性的概率</p>
<h4 id="拉普拉斯平滑"><a href="#拉普拉斯平滑" class="headerlink" title="拉普拉斯平滑"></a>拉普拉斯平滑</h4><p>通俗的说，拉普拉斯平滑即在计算概率的时候，分别在分子上加1，分母上加属性的取值种类。</p>
<h4 id="朴素贝叶斯优化"><a href="#朴素贝叶斯优化" class="headerlink" title="朴素贝叶斯优化"></a>朴素贝叶斯优化</h4><ol>
<li>可以将涉及到的所有概率先计算好存储起来，在进行预测时只需要“查表”即可进行判别。</li>
<li>当数据有多属性时，涉及到多属性连乘问题，可以将原连乘问题转换为对数连加问题加快计算速度。<h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4></li>
</ol>
<ul>
<li>优点：对小规模数据表现很好，适合多分类任务</li>
<li>缺点：对输入数据的表达形式很敏感<h2 id="半朴素贝叶斯分类器"><a href="#半朴素贝叶斯分类器" class="headerlink" title="半朴素贝叶斯分类器"></a>半朴素贝叶斯分类器</h2></li>
<li>基本想法是适当考虑一部分属性间的相互依赖信息，从而既不需要进行完全联合概率计算，又不至于彻底忽略了比较性强的属性依赖关系。</li>
<li>“独依赖估计”是半朴素贝叶斯分类器最常用的一种策略，所谓“独依赖”就是假设每个属性在类别之外最多仅依赖一个其他属性。</li>
<li>半朴素贝叶斯不是很常见，具体细节见书p154</li>
</ul>
<h2 id="贝叶斯网络"><a href="#贝叶斯网络" class="headerlink" title="贝叶斯网络"></a>贝叶斯网络</h2><p>也称“信念网络”，借助有向无环图来刻画属性之间的依赖关系，并使用条件概率表来描述属性的联合概率分布。</p>
<h4 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h4><h4 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h4><h4 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h4><p>吉布斯采样，EM算法</p>
<h1 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h1><p>通过构建并结合多个学习器来完成学习任务，总体思路是：1. 先产生一组“个体学习器”，再用某种策略将他们结合起来。</p>
<ul>
<li>同质的个体学习器也可以称为“基学习器”</li>
<li>异质集成中的个体学习器由不同算法组成，常称为“组件学习器”<br>集成学通过多个学习器的组合，通常会有比单一学习器更显著的泛化性能。<br>如何产生“好而不同”的个体学习器是集成学习的研究核心。<br>目前的集成学习方法大致可以分为两类：</li>
</ul>
<ol>
<li>个体学习器之间存在强依赖关系，必须串行生成序列化方法，代表是Boosting。</li>
<li>个体学习器之间不存在强依赖关系，可同时生成的并行化方法，代表是Bagging和随机森林</li>
</ol>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>Boosting是一族可将弱学习器提升为强学习器的方法：这族算法工作原理类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器的错误样本更受关注然后基于调整后的样本分布训练下一个基学习器。最后将这些基学习器组合到一起。</p>
<ul>
<li>优点：<ol>
<li>低泛化误差</li>
<li>容易实现，准确率较高，不需要大量调参</li>
</ol>
</li>
<li>缺点：<ol>
<li>对异常点过于敏感<h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h4></li>
</ol>
</li>
<li>常规公式推导</li>
<li>基于加性模型，即学习基学习器的线性组合来最小化指数损失函数</li>
</ul>
<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>基本思想是对训练集进行采样，产生出若干个不同的子集，再从每个子集中训练一个基学习器。常使用的采样方法为“自助采样法”。<br>我们可以采样出T个含有m个样本的采样集，用每个采样集训练出一个基学习器，字啊将这些基学习器进行结合就是Bagging的基本流程。<br>Bagging对于分类任务采用简单投票法，对于回归任务采用简单平均法。<br>对于每个基学习器的包外样本，可以用其进行泛化性能估计或者辅助剪枝（决策树）</p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>随机森林是在Bagging的基础上进一步在决策树的训练过程中引入了 <strong>随机属性选择</strong>。<br>在RF中，对基决策树的每个节点，<strong>先从该节点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分，这里的参数k控制了随机性的引入程度，若k=d，则基决策树的构建和传统决策树相同；若k=1，则随机选择一个属性用于划分，一般情况下推荐k=log2d</strong><br>RF中的基学习器的多样性不仅仅来自于样本扰动（对原始数据集进行自助采样），还来自属性随机。</p>
<h2 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h2><ol>
<li>对于回归问题：简单平均法、加权平均法</li>
<li>对于分类问题：绝对多数投票法，相对对数投票法，加权投票法。</li>
</ol>
<h2 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h2><p>先从初始数据集训练出初始学习器，然后再生成一个新数据集用于训练次级学习器。在这个新的数据集中，初级学习器的输出被当做样例输入特征，儿初始样本的标记被当做样例标记。</p>
<h2 id="集成学习的多样性度量"><a href="#集成学习的多样性度量" class="headerlink" title="集成学习的多样性度量"></a>集成学习的多样性度量</h2><p>见书P186页</p>
<h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><h2 id="性能度量-1"><a href="#性能度量-1" class="headerlink" title="性能度量"></a>性能度量</h2><ul>
<li>用来评估聚类效果的好坏<ul>
<li>同一簇的样本尽可能的彼此相似，不同簇的样本尽可能不同。</li>
<li>簇内相似度尽可能高，簇间相似度尽可能低</li>
</ul>
</li>
<li>两类性能度量：<ol>
<li>将聚类结果与某个参考模型进行比较，称为”外部目标”</li>
<li>直接考察聚类结果而不利用任何参考模型，称为“内部目标”·</li>
</ol>
</li>
<li>三个聚类性能度量外部指标：<ol>
<li>Jaccard系数</li>
<li>FM系数</li>
<li>Rand指数</li>
</ol>
<ul>
<li>上述性能度量都在零一之间，且越大越好</li>
</ul>
</li>
<li>两个聚类性能度量内部指标<ol>
<li>DB指数</li>
<li>Dunn指数</li>
</ol>
<ul>
<li>DBI越小越好，DI越大越好</li>
</ul>
</li>
</ul>
<h2 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h2><ul>
<li>闵可夫斯基距离度量：<ol>
<li>当p=2时，即为欧氏距离</li>
<li>当p=1时，即为曼哈顿距离</li>
</ol>
</li>
<li>使用闵可夫斯基距离时，注意只能针对有序属性特征</li>
<li>对于无序属性，可以采用VDM</li>
<li>对于一般问题，可以将闵可夫斯基度量和VDM相结合，前者处理有序属性，后者处理无序属性</li>
</ul>
<h2 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h2><h3 id="k均值算法"><a href="#k均值算法" class="headerlink" title="k均值算法"></a>k均值算法</h3><ul>
<li>优点：思想简单，理论成熟，既可以回归也可以分类</li>
<li>缺点：计算量大，样本不平衡问题，需要大量内存<h4 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h4></li>
</ul>
<ol>
<li>设定聚类簇数为k，随机选取k个样本作为初始均值向量。</li>
<li>考察剩余样本，分别计算剩余样本到这k个均值向量的距离，并将其加入距离最近的聚类簇中</li>
<li>计算每个新聚类簇的均值向量，返回第二步直至收敛。<h3 id="学习向量量化LVQ"><a href="#学习向量量化LVQ" class="headerlink" title="学习向量量化LVQ"></a>学习向量量化LVQ</h3><h3 id="高斯混合聚类算法"><a href="#高斯混合聚类算法" class="headerlink" title="高斯混合聚类算法"></a>高斯混合聚类算法</h3>见书206页<h3 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h3>假设聚类结构能通过样本分布的紧密程度确定。<h4 id="DBSCAN-密度聚类算法"><a href="#DBSCAN-密度聚类算法" class="headerlink" title="DBSCAN 密度聚类算法"></a>DBSCAN 密度聚类算法</h4><h3 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h3>试图在不同层次对数据集进行划分，从而形成树形的聚类结构。<h4 id="AGNES-层次聚类算法"><a href="#AGNES-层次聚类算法" class="headerlink" title="AGNES 层次聚类算法"></a>AGNES 层次聚类算法</h4></li>
</ol>
<h1 id="第十章-降维与度量学习"><a href="#第十章-降维与度量学习" class="headerlink" title="第十章 降维与度量学习"></a>第十章 降维与度量学习</h1><h2 id="k近邻学习"><a href="#k近邻学习" class="headerlink" title="k近邻学习"></a>k近邻学习</h2><ul>
<li>分类任务中使用投票法，回归任务中使用平均法，也可以使用加权平均法</li>
<li>是懒惰学习 lazy learning的著名代表，没有显式的训练过程。（相应的，那些在训练阶段就对样本进行学习处理的方法称为急切学习 eager learning）</li>
<li>k值越大，模型越简单，</li>
</ul>
<h2 id="低维嵌入"><a href="#低维嵌入" class="headerlink" title="低维嵌入"></a>低维嵌入</h2><p>在高维情形下出现的数据样本稀疏，距离计算困难等问题被称为维度灾难（curse of dimensionality）</p>
<h3 id="MDS算法"><a href="#MDS算法" class="headerlink" title="MDS算法"></a>MDS算法</h3><p>见书P227页</p>
<h2 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析 PCA"></a>主成分分析 PCA</h2><p>见书229页</p>
<h2 id="核化线性降维"><a href="#核化线性降维" class="headerlink" title="核化线性降维"></a>核化线性降维</h2><p>非线性降维的一种方法，是基于核技巧对线性降维方法进行核化</p>
<h2 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h2><h3 id="等度量映射"><a href="#等度量映射" class="headerlink" title="等度量映射"></a>等度量映射</h3><h3 id="局部线性嵌入"><a href="#局部线性嵌入" class="headerlink" title="局部线性嵌入"></a>局部线性嵌入</h3><h2 id="度量学习"><a href="#度量学习" class="headerlink" title="度量学习"></a>度量学习</h2><h1 id="第11章-特征选择与稀疏学习"><a href="#第11章-特征选择与稀疏学习" class="headerlink" title="第11章 特征选择与稀疏学习"></a>第11章 特征选择与稀疏学习</h1><h1 id="补充-1"><a href="#补充-1" class="headerlink" title="补充"></a>补充</h1><p>5.6 逻辑回归模型 vs 最大熵模型 MaxEnt</p>
<p>简单粗暴的说：逻辑回归跟最大熵模型没有本质区别。逻辑回归是最大熵对应为二类时的特殊情况，也就是说，当逻辑回归扩展为多类别的时候，就是最大熵模型。</p>
<p>最大熵原理：学习概率模型的时候，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。</p>
<h2 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h2><p>有时候因为样本的产生和隐含变量有关（隐含变量是不能观察的），而求模型的参数时一般采用最大似然估计，由于含有了隐含变量，所以对似然函数参数求导是求不出来的，这时可以采用EM算法来求模型的参数的（对应模型参数个数可能有多个），EM算法一般分为2步：</p>
<p>　　E步：选取一组参数，求出在该参数下隐含变量的条件概率值；</p>
<p>　　M步：结合E步求出的隐含变量条件概率，求出似然函数下界函数（本质上是某个期望函数）的最大值。</p>
<p>　　重复上面2步直至收敛。</p>
<h4 id="使用Jensen不等式确定下界"><a href="#使用Jensen不等式确定下界" class="headerlink" title="使用Jensen不等式确定下界"></a>使用Jensen不等式确定下界</h4><h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>原理，于GRU的区别</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/22/SICP第一章笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/22/SICP第一章笔记/" itemprop="url">SICP第一章:构造过程抽象</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-22T00:00:00+09:00">
                2018-03-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Programming-Language/" itemprop="url" rel="index">
                    <span itemprop="name">Programming Language</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/22/SICP第一章笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/03/22/SICP第一章笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>SICP（《Structure and Interpretation of Computer Science》）被无数外国程序员誉为最值得读的神书之一，同时身在PL研究室的我，EOPL和SICP都是不得不读的书。在这将这本书的读书笔记整理下来。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/03/22/SICP第一章笔记/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/11/基于深度学习的电影推荐系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dongfang Li">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Black Feather">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/03/11/基于深度学习的电影推荐系统/" itemprop="url">基于深度学习的电影推荐系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-11T00:00:00+09:00">
                2018-03-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/11/基于深度学习的电影推荐系统/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/03/11/基于深度学习的电影推荐系统/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>本项目是使用python3 + tensorflow，搭建一个基于卷积神经网络模型的离线电影推荐系统，电影数据集用的是MovieLens。核心思想是对于电影和用户的不同属性，构建多个神经网络进而获得每个属性的特征表示。使用这些特征表示构建用户特征矩阵和电影特征矩阵，进而完成：TopK电影推荐，相似用户查找等功能。<br>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2018/03/11/基于深度学习的电影推荐系统/#more" rel="contents">
              Read more &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Dongfang Li</p>
              <p class="site-description motion-element" itemprop="description">My blog about programming and machine learning</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/YHfeather" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.facebook.com/dongfang.li.790" target="_blank" title="FB Page">
                      
                        <i class="fa fa-fw fa-facebook"></i>FB Page</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dongfang Li</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://blackfeather.disqus.com/count.js" async></script>
    

    

  




	





  














  





  

  

  

  
  

  

  

  

</body>
</html>
